---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# ğŸ™ˆ About me

I am a PhD student in [LIESMARS](https://liesmars.whu.edu.cn/), [Wuhan University](https://www.whu.edu.cn/). My advisors are Prof. [Zhen Dong](https://dongzhenwhu.github.io/index.html) and Prof. [Bisheng Yang](https://3s.whu.edu.cn/info/1025/1415.htm). Previously, I obtained my B.Eng degree at [School of Remote Sensing and Information Engineering](https://rsgis.whu.edu.cn/), Wuhan University.

My research interests lie in the road scene reconstruction and understanding using images and point clouds. If you are interested in my research, feel free to contact me at <liuchongwhu@whu.edu.cn>!

I am a member of [WHU-USI3DV](https://github.com/WHU-USI3DV), please check advancements on point cloud processing including enhancement, registration, localization, segmentation, detection, etc.

# ğŸ“ Publications
**\* denotes equal contributions and â€  denotes the corresponding author.**

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2026</div><img src='../images/SSVI-3D.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

SVII-3D: Advancing Roadside Infrastructure Inventory with Decimeter-level 3D Localization and Comprehension from Sparse Street Imagery

**Chong Liu**, Luxuan Fu, Yang Jia, Zhen Dong<sup>&dagger;</sup>, Bisheng Yang

<span style="color:#1E90FF">**Arxiv 2026**</span>

[[Paper]](https://arxiv.org/abs/2601.10535)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Arxiv 2026</div><img src='../images/Attribute.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Unleashing the Capabilities of Large Vision-Language Models for Intelligent Perception of Roadside Infrastructure

Luxuan Fu<sup>*</sup>, **Chong Liu<sup>*</sup>**, Bisheng Yang<sup>&dagger;</sup>, Zhen Dong

<span style="color:#1E90FF">**Arxiv 2026**</span>

[[Paper]](http://arxiv.org/abs/2601.10551)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AIC 2025</div><img src='../images/OpenSet.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Training-free open-set 3D inventory of transportation infrastructure by combining point clouds and images

**Chong Liu**, Mingyu Xie, Changzheng Yuan, Fuxun Liang<sup>&dagger;</sup>, Zhen Dong, Bisheng Yang

<span style="color:#1E90FF">**Automation in Construction 2025 (IF: 11.5)**</span>

[[Paper]](https://www.sciencedirect.com/science/article/pii/S0926580525004170)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TITS 2024</div><img src='../images/INF-PCA.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

INF-PCA: Implicit Neural Field-Based Interactive Point Cloud Semantic Annotation

**Chong Liu<sup>*</sup>**, Xu Han<sup>*</sup>,  Weihong Huang, Chen Long, Wang Wang, Zhen Dong<sup>&dagger;</sup>, Bisheng Yang<sup>&dagger;</sup>

<span style="color:#1E90FF">**IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS 2024 (IF: 8.4)**</span>

[[Paper]](https://ieeexplore.ieee.org/document/10767851)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ISPRS 2024</div><img src='../images/Urban3D.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

WHU-Urban3D: An urban scene LiDAR point cloud dataset for semantic instance segmentation

Xu Han<sup>*</sup>, **Chong Liu<sup>*</sup>**, Yuzhou Zhou, Kai Tan, Zhen Dong<sup>&dagger;</sup>, Bisheng Yang<sup>&dagger;</sup>

<span style="color:#1E90FF">**ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING 2024 (IF: 12.2)**</span>
<br>
<span style="color:#FF8C00; font-weight:bold">ğŸ† ESI Highly Cited Paper !</span>

[[Paper]](https://www.sciencedirect.com/science/article/pii/S0924271624000522), [[DataSet]](https://whu3d.com/)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RS 2024</div><img src='../images/Zebra.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Three-Dimensional Reconstruction of Zebra Crossings in Vehicle-Mounted LiDAR Point Clouds

Zhenfeng Zhao, Shu Gan, Bo Xiao, Xinpeng Wang, **Chong Liu<sup>&dagger;</sup>**

<span style="color:#1E90FF">**Remote Sensing 2024 (IF: 4.1)**</span>

[[Paper]](https://www.mdpi.com/2072-4292/16/19/3722)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ISPRS 2021</div><img src='../images/Marking.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

A two-stage approach for road marking extraction and modeling using MLS point clouds

Xiaoxin Mi, Bisheng Yang<sup>&dagger;</sup>, Zhen Dong<sup>&dagger;</sup>, **Chong Liu**, Zeliang Zong, Zhenchao Yuan

<span style="color:#1E90FF">**ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING 2021 (IF: 11.7)**</span>

[[Paper]](https://www.sciencedirect.com/science/article/pii/S0924271621001970?via%3Dihub)
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AIC 2025</div><img src='../images/Wangwang.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

Unified data synthesis for automated 3D Visual Inspection and digital twinning of bridges

Wang Wang, Mingjing Xu, Zhen Cao, Jingzi Guo, **Chong Liu**, Haowei Zhang, Xiaoling Zhang

<span style="color:#1E90FF">**Automation in Construction 2025 (IF: 11.5)**</span>

[[Paper]](https://www.sciencedirect.com/science/article/pii/S0926580525007812)
</div>
</div>

# ğŸ’¡ National Invention Patent
- **åˆ˜ç¿€**,è‘£éœ‡,ç±³æ™“æ–°.ä¸€ç§åŸºäºè½¦è½½æ¿€å…‰ç‚¹äº‘çš„æ–‘é©¬çº¿ä¸‰ç»´é‡å»ºæ–¹æ³•åŠç³»ç»Ÿ:CN202210729496.0[P]. **å·²æˆæƒ**
- æ¨å¿…èƒœ,**åˆ˜ç¿€**,ç±³æ™“æ–°,ç­‰.è”åˆç‚¹äº‘å¼ºåº¦å’Œå‡ ä½•ç»“æ„çš„é“è·¯æ ‡å¿—æå–æ–¹æ³•åŠç³»ç»Ÿ:CN202111274991.9[P]. **å·²æˆæƒ**
- **åˆ˜ç¿€**,æœ±è´µæ–¹,æå¼º,ç­‰.åŸºäºéšå¼ç¥ç»åœºç½‘ç»œçš„ç‚¹äº‘äº¤äº’å¼è¯­ä¹‰æ ‡æ³¨æ–¹æ³•å’Œè£…ç½®:CN202411062689.0[P]. **å·²æˆæƒ**
- è‘£éœ‡,**åˆ˜ç¿€**,æ¢ç¦é€Š.å¼€æ”¾é›†äº¤é€šåŸºç¡€è®¾æ–½ä¸‰ç»´æ•°å­—åŒ–å¤§æ¨¡å‹æ„å»ºæ–¹æ³•ä¸è£…ç½®:CN202510601387.4[P]. **å·²æˆæƒ**

# ğŸ‘» Honors and Awards
- *2023.10*, **åœ°ç†ä¿¡æ¯ç§‘æŠ€è¿›æ­¥å¥–äºŒç­‰å¥–** "åŸºäºæ¿€å…‰ç‚¹äº‘çš„åŸå¸‚é“è·¯ç©ºé—´ä¿¡æ¯æ™ºèƒ½æå–å…³é”®æŠ€æœ¯ä¸åº”ç”¨" ï¼ˆä¸ªäººæ’å 7ï¼‰
- *2023.09*, **æµ‹ç»˜ç§‘å­¦æŠ€æœ¯å¥–äºŒç­‰å¥–** "åœ°ç†å®ä½“æ•°æ®é«˜æ•ˆç”Ÿäº§ä¸æœåŠ¡å…³é”®æŠ€æœ¯åŠåº”ç”¨" ï¼ˆä¸ªäººæ’å 8ï¼‰
- *2022.09*, **æµ‹ç»˜ç§‘å­¦æŠ€æœ¯å¥–äºŒç­‰å¥–** "é¢å‘æ™ºèƒ½äº¤é€šæ—¶ç©ºä¿¡æ¯æœåŠ¡çš„ä¸‰ç»´æ¿€å…‰ç‚¹äº‘æ•°æ®è‡ªåŠ¨å¤„ç†å…³é”®æŠ€æœ¯ç ”ç©¶" ï¼ˆä¸ªäººæ’å 8ï¼‰
